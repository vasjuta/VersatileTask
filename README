For challenge description see ./task_description

Start Disclaimer:

No hands-on experience in the field of CV whatsoever. All the knowledge is from ML courses I took years ago.
Thus some significant time (see further) was spent on research and wrapping my head around.
The sources that were most helpful are listed in ./research_resources
The presented [MVP] project is a compilation of ideas and solutions found in those resources.
It is neither complete, nor the most efficient but it does provide surprisingly decent results.

Brief solution description:

The given dataset of 54 paintings (9 per each of 6 artists) doesn't allow any ML solution to be proposed.
There may be some advanced techniques from the Few-Shot Learning (took a quick look) but it was out of scope time and effort-wise.
Thus, additional data had to be collected and it indeed was. Overall I had 515 images spread somewhat equally between 6 artists in question.
Still, this amount is hardly sufficient so data augmentation was put into action.
Eventually, it was enough for a good baseline model which showed 97% and 83% accuracy at training and cross-validation respectively.
(See further for more on results).

The solution is based on CNN approach with ResNet50 being a pretrained architecture.
There was no time to play with all the [hyper]parameters so I went with the baseline solution from one of the above mentioned resources.
However, small tweaks had to be made, like lowering number of epochs (5 initial tail training, then freezing the ResNet layers, and 10 more) to reduce computation time, and adjusting the batch size (from usual 16 to 4) to have more batches for training. Obviously, there is a huge room for improvement there. More epochs should yield better results.
Train/Validation split was chosen to be 75/25, again, to compensate for the size of data with regard to validation samples.

Results:
See /Results directory.

classification_report.log - classification report for training/validation
Figure_1.png - training/validation accuracy/loss plots
confusion_matrix.png - classification confusion matrix
sample_batch_classification.txt - predictions, true labels, and probabilities for 45 random paintings 

API:
Sanic framework/server was chosen to implement the required functionality end to end.
It is very simple and quickly to develop and set up. See README under /WebServer

WebServer/main.py contains the endpoint (plus the handshaker) calling the correspondent method from ClassifierAPI.
The latter serves as facade to ClassificationEngine.py which does all the work (training, testing, inference).
A screenshot of a sample API call via postman can be found at /results/api_call_postman.png
NB Since no spec for request format was provided, I went with the easiest (both for the development and a potential user) option -
a painting to classify is given by URL.

End Disclaimer:
The solution is a two days project in a [partially] new domain and as such lacks many vital [and usual in another setting] things.
Those include:
error handling, logging, proper testing, documentation, comments, refactoring, generalization, configs, project hierarchy, and so forth.

Approximate effort time splits are as follows:

* Research - 3-4 hours
* Implementation - 4-5 hours
* Model training [on local CPU] - 40-70 mins * 4-5 times - 1-2 hours of net time (was paralleled with other work)
* API + testing - 1-2 hours
* Debugging, installations, tensorflow glitches, etc. - 2-3 hours
* Additional data scraping - 0.5 hours
* Writing (and editing) this README - 1-2 hours

* Total - 2 full work days, plus a bit




